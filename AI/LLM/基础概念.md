## 相关概念

### LLM

LLM（Large Language Model）即大型语言模型，简称 大模型。

大模型是一种采用大量数据进行训练、深度学习算法构建的语言模型，其核心思想是通过大规模的无监督训练学习自然语言的模式和结构，在一定程度上模拟人类的语言认知和生成过程。

### 模型训练

模型训练是机器研究中的一项重要任务，它是通过研究数据来构建一个数学模型，以便能够预测未知数据的结果或行为。模型训练是通过使用己知的数据集来调整模型中的参数和权重，以最大程度地提高模型的预测准确性。

模型训练的过程可以简单概括为以下几个步骤：

1. 数据收集：首先需要收集足够的数据作为训练集。这些数据应该包含多个特征或属性，以便让模型可以从中研究。
2. 数据预处理：在进行模型训练之前，需要对收集到的数据进行预处理。这包括数据清洗、处理缺失值、处理异常值、特征选择和转换等操作，以提高训练效果。
3. 模型选择：根据具体问题的需求，选择合适的模型进行训练。常见的模型包括线性回归、决策树、支持向量机、神经网络等。
4. 模型训练：使用预处理过的数据集来训练选定的模型。训练的过程就是调整模型中的参数和权重，使模型能够更好地拟合数据。
5. 模型评估：训练完成后，需要对模型进行评估，以了解模型的性能。常用的评估指标包括准确率、精确率、召回率、F1分数等。

模型训练是机器学习中非常重要的一环，通过不断优化模型可以获得更准确的预测结果。随着数据量的增加和算法的不断发展，模型训练的技术也在不断进步。理解和掌握模型训练的基本概念和方法，将有助于在实际应用中应用机器学习算法解决问题。

**最佳实践：**

- 数据预处理：清洗数据、处理缺失值、特征缩放等。
- 特征工程：选择合适的特征、进行特征变换和特征交互等。
- 参数调优：使用网格搜索或贝叶斯优化等方法寻找最佳参数。
- 模型评估：使用交叉验证和多个评估指标来评估模型性能。

**常见问题：**

- 过拟合（对训练过的数据表现较好，对未训练的数据表现较差）：增加训练数据、使用正则化技术、简化模型等。
- 欠拟合（对训练过的数据表现也不好）：增加模型复杂度、改进特征工程等。
- 训练时间过长：使用分布式训练、优化模型和数据等。



### 向量构建

向量是表示数据的一种数学结构，具有三个基本属性：方向、大小和数量。向量可以表示多维空间中的点或线，也可以表示单维度空间中的向量。在向量空间中，每个向量都可以表示为一个点向量、线性向量或多维向量。向量的模( magnitude )表示向量的大小，是向量长度的度量。向量的模是向量在单位球面上的分量大小。向量的夹角( angle )表示向量在单位球面上的切向量，是向量与旋转中心之间的夹角。

向量计算是向量空间中的基本操作之一，包括向量加法、向量减法、向量乘法、向量加法和减法等。向量计算可以分为线性运算和非线性运算。线性运算包括向量加法、向量减法和向量乘法等。非线性运算包括向量加法和减法，以及旋转、缩放等操作。

向量的模运算是向量计算中最基本的操作之一，它表示向量的长度。向量的模运算可以分为绝对值运算和模长运算两种。绝对值运算包括向量的正数和负数运算，以及绝对值和负数的和运算。模长运算包括向量的模和向量的模长运算，以及向量的模长和模长乘积运算。

### 置信度

置信度也称为 可靠度，或置信水平、置信系数，即在抽样对总体参数作出估计时，由于样本的随机性，其结论总是不确定的。因此，采用一种概率的陈述方法，也就是数理统计中的区间估计法，即估计值与总体参数在一定允许的误差范围以内，其相应的概率有多大，这个相应的概率称作置信度。

在统计学中，一个概率样本的**置信区间**(Confidence interval)是对这个样本的某个总体参数的区间估计。置信区间展现的是这个参数的真实值有一定概率落在测量结果的周围的程度。置信区间给出的是被测量参数的测量值的可信程度，即前面所要求的"一定概率"。这个概率被称为**置信水平**。

### 意图和词槽

意图：也就是用户的目的，要做什么（what）。分为 对话意图 和 问答意图。

词槽：满足用户对话意图的关键信息或限定条件，可以理解为用户需要提供的筛选条件。词槽是描述意图的关键信息，可以用 where、when、who 等表示。

### CoT

CoT（Chain of Thought）即思维链。是指把逻辑较为复杂的问题进行拆解，通过一系列有逻辑关系的思考，形成完整的思考的过程。

对于一些逻辑较为复杂的问题，直接向大模型提问可能会得到不准确的回答，但是如果以prompt的方式在输入中给出有逻辑的解题步骤（即将复杂问题拆解为多个子问题解决再从中抽取答案）的示例后再提出问题，大模型就能给出正确题解。

### ToT

ToT（Tree of Thoughts）即思维树。是一种创新的框架，旨在增强大模型的推理能力。它模拟了人类解决问题的认知策略，使 LLM 能够以结构化的方式探索多种可能的解决方案，类似于树状分支路径。

将问题分解为一系列连贯的思维步骤，每个步骤都是一个语言序列，作为问题解决的中间步骤。然后为每个树状结构的状态生成潜在的思维步骤，评估每个状态的潜在价值，作为搜索算法的启发式标准，最后使用不同的搜索算法来探索思维树，以找到最优解决方案。

### Zero-Shot

零样本，零样本学习和零样本提示。

**零样本学习：**在训练集中没有某个类别的样本，但在测试集中出现了这个类别。我们需要模型在训练过程中，即使没有接触过这个类别的样本，但仍然可以通过对这个类别的描述，对没见过的类别进行分类。

**零样本提示：**模型只根据任务的描述生成响应，在提示词中不提供任何示例。

### Few-Shot

少样本，少样本学习和少样本提示。

**少样本学习：**在模型训练过程中，如果每个类别只有少量样本（一个或几个），研究人员希望机器学习模型在学习了一定类别的大量数据后，对于新的类别，只需要少量的样本就能快速学习。

**少样本提示：**在提示词中通过少量样本引导模型对特定任务进行学习和执行，例如通过提供少量风格或主题示例，引导模型产出具有相似风格或主题的创作。

### RAG

RAG（Retrieval-Augmented Generation）是一种结合了检索和生成技术的模型，主要用于自然语言处理任务中。 RAG通过从外部知识库中检索相关信息，然后利用这些信息来指导模型的生成过程，从而提高预测的质量和准确性。这种技术特别适用于知识密集型的任务，如问答系统、文档生成和智能助手等。

**RAG的工作原理**

RAG的工作原理可以分为以下几个步骤：

1. 检索：当模型需要生成文本或回答问题时，它会从一个庞大的文档集合中检索出相关的信息。
2. 生成：利用检索到的信息来指导文本的生成，从而提高预测的质量和准确性。

**RAG的优势和应用场景**

RAG的优势包括：

- 知识增强：通过检索外部知识库，RAG能够结合更多的背景信息，生成更准确和丰富的内容。
- 可解释性：RAG的生成过程更加透明，用户可以更容易理解模型的决策依据。
- 适用场景广泛：适用于问答系统、文档生成、智能助手等多个自然语言处理任务。

### Prompt

大模型中的 “Prompt” 即提示词，是用于引导大语言模型生成特定内容或执行特定任务的一段引导性文字。Prompt 是一个由文本组成的输入，用以触发模型生成特定的输出。它为模型提供了上下文和方向，确保生成的内容符合用户需求。

- **作用**

  通过精心设计的 Prompt，可以引导模型生成高质量的文本、回答问题、进行推理等，在自然语言处理、问答系统、文本生成等领域有着广泛的应用。

- **组织形式**
  
  - 非结构化**：没有固定结构，可以是一句话、一段文字或杂乱的文字片段，比较随意自由。**
  - 结构化**：按照一定格式组织，通常以 markdown 形式书写，分段且带小标题，结构相对严谨，架构可固定可调整。**
- **使用方式**
  - **系统提示词（System Prompt）**：全局全过程提示词，一般在预训练模型、基于预训练模型创建的新模型、API 调用中使用，由模型创建者、脚本开发者或用户添加，相当于给新模型 “下定义”。
  - **用户提示词（User Prompt）**：一般性提示词，由用户根据实际需求在与大模型的对话中使用，也可在 API 调用时使用，形式和内容上可与系统提示词一样。