# CPU

## CPU占用率

即cpu的使用率，单核cpu通常临界点在50%，70%，90%。

- < 50%：认为cpu工作状态正常。
- 50%～70%：认为cpu工作状态饱和。
- 70%～90%：认为cpu工作状态繁忙。通常在大于70%时，就开始预警。
- \>90%：认为cpu处于性能瓶颈。
- 以上分析以单核为例。如果是多核，需要按空闲率倒过来算，比如 双核、空闲率保证 30%，那么 cpu 的实际使用率是170%。



## CPU队列

- **CPU的运行队列统计**:在Linux里，一个进程，对于线程来说要不在运行，要不在阻塞。一个阻塞的进程可能是在等着一些io的数据处理，或者等待一些系统调用。当这些进程是运行状态，等待CPU处理的任务数就叫运行队列。任务越多队列越长，运行队列越长表示CPU的压力就越大。

- top 命令打印结果中的 load average 就表示cpu的队列信息。

  ``` shell
  [root@VM-0-10-centos ~]# top
  top - 15:18:44 up 1 day, 21:54,  1 user,  load average: 0.00, 0.01, 0.05
  Tasks: 123 total,   1 running,  80 sleeping,   0 stopped,   0 zombie
  
  # 第一行 load average 说明：
  # 0.00 过去一分钟系统的平均负载
  # 0.01 过去五分钟系统的平均负载
  # 0.05 过去十五分钟系统的平均负载
  # 
  # 可以看出系统负载是上升、平稳、下降的趋势。系统忙不忙的判断标准：
  # 统计值 <= cpu 核数，表示不忙
  # 统计值 介于 cpu核数 和 cpu核数*3 之间，不确定
  # 统计值 大于 cpu核数*3 ，表示繁忙
  #
  # 第二行 Tasks 说明：
  # running 表示正在 CPU 上运行的和将要被调度运行的进程数；
  # sleeping 通常是等待事件(比如 IO 操作)完成的任务，细分可以包括 interruptible 和 uninterruptible 的类型；
  # stopped 是一些被暂停的任务，通常发送 SIGSTOP 或者对一个前台任务操作 Ctrl-Z 可以将其暂停；
  # zombie 僵尸任务，虽然进程终止资源会被自动回收，但是含有退出任务的 task descriptor 需要父进程访问后才能释放，这种进程显示为 defunct 状态，无论是因为父进程提前退出还是为 wait 调用，出现这种进程都应该格外注意程序是否设计有误。
  ```



## CPU中断

中断是系统响应硬件设备请求的一种机制，它会打断进程的正常调度和执行，然后调用内核中的中断处理程序来响应设备的请求。

- 硬中断：由与系统相连的外设(比如网卡、硬盘)自动产生的。主要是用来通知操作系统系统外设状态的变化。比如当网卡收到数据包的时候，就会发出一个中断。我们通常所说的中断指的是硬中断(hardirq)。

- 软中断：由软中断指令产生。为了满足实时系统的要求，中断处理应该是越快越好。linux为了实现这个特点，当中断发生的时候，硬中断处理那些短时间就可以完成的工作，而将那些处理事件比较长的工作，放到中断之后来完成，也就是软中断(softirq)来完成。

- 中断嵌套：Linux下硬中断是可以嵌套的，但是没有优先级的概念，也就是说任何一个新的中断都可以打断正在执行的中断，但同种中断除外。软中断不能嵌套，但相同类型的软中断可以在不同CPU上并行执行。

- 软中断指令：int是软中断指令。中断向量表是中断号和中断处理函数地址的对应表。int n - 触发软中断n。相应的中断处理函数的地址为：中断向量表地址 + 4 * n。

  ``` shell
  [root@VM-0-10-centos ~]# top
  top - 15:41:25 up 1 day, 22:17,  1 user,  load average: 0.29, 0.18, 0.11
  Tasks: 113 total,   1 running, 112 sleeping,   0 stopped,   0 zombie
  %Cpu(s):  0.3 us,  0.7 sy,  0.0 ni, 99.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
  
  # 说明：
  # 0.3% us（user） — 用户态占用CPU的百分比。CPU 在低nice值(高优先级)用户态所占用CPU的时间(nice<=0)。
  # 
  # 0.7% sy（system） — 内核态占用CPU的百分比。CPU 处于内核态所占用的时间，操作系统通过系统调用(system call)从用户态陷入内核态，以执行特定的服务；通常情况下该值会比较小，但是当服务器执行的 IO 比较密集的时候，该值会比较大。
  # 
  # 0.0% ni — 改变过优先级的进程占用CPU的百分比。CPU 在高 nice 值(低优先级)用户态以低优先级运行占用的时间(nice>0)。默认新启动的进程 nice=0，是不会计入这里的，除非手动通过 renice 或者 setpriority() 的方式修改程序的nice值。
  
  # 99.0% id — CPU 在空闲状态(执行 kernel idle handler )所占用的时间。
  
  # 0.0% wa — IO等待占用CPU的百分比。
  # 0.0% hi — 硬中断（Hardware IRQ）占用CPU的百分比
  # 0.0% si — 软中断（Software Interrupts）占用CPU的百分比
  
  # 0.0% st（steal） — 在虚拟机情况下才有意义，因为虚拟机下 CPU 也是共享物理 CPU 的，所以这段时间表明虚拟机等待 hypervisor 调度 CPU 的时间，也意味着这段时间 hypervisor 将 CPU 调度给别的 CPU 执行，这个时段的 CPU 资源被“stolen”了。
  
  # ===============分析================
  # 当 user 占用率过高的时候，通常是某些个别的进程占用了大量的 CPU，这时候很容易通过 top 找到该程序；此时如果怀疑程序异常，可以通过 perf 等思路找出热点调用函数来进一步排查；
  
  # 当 system 占用率过高的时候，如果 IO 操作(包括终端 IO)比较多，可能会造成这部分的 CPU 占用率高，比如在 file server、database server 等类型的服务器上，否则(比如>20%)很可能有些部分的内核、驱动模块有问题；
  
  # 当 nice 占用率过高的时候，通常是有意行为，当进程的发起者知道某些进程占用较高的 CPU，会设置其 nice 值确保不会淹没其他进程对 CPU 的使用请求；
  
  # 当 iowait 占用率过高的时候，通常意味着某些程序的 IO 操作效率很低，或者 IO 对应设备的性能很低以至于读写操作需要很长的时间来完成；
  
  # 当 irq/softirq 占用率过高的时候，很可能某些外设出现问题，导致产生大量的irq请求，这时候通过检查 /proc/interrupts 文件来深究问题所在；
  ```



## CPU上下文切换

<font style="color:red">一般上下文切换在数百到一万之内，上下文切换超过1万，很可能遇到性能问题。</font>

- Linux 是一个多任务的操作系统，它支持远大于CPU数量的任务同时运行，当然并不是真正的同时运行，是每个任务轮流执行CPU分给他们的时间片，让人感觉是同时在运行。

- 每一个任务运行前，CPU都需要知道任务从哪里加载，又从哪里运行，也就是说，需要系统事先设置好CPU寄存器。

- CPU寄存器包含指令寄存器(IR)和程序计数器(PC)。他们用来暂存指令、数据、当前指令地址、程序运行的下一条指令地址，这些都是任务运行时的必要环境。因此也被称作**CPU上下文**。

- 上下文切换就是把前一个任务的CPU上下文保存起来，然后加载新任务的上下文加载到这些指令寄存器(IR)和程序寄存器(PC)等寄存器中。这些被保存下来的上下文会存储在操作系统的内核空间中，等待任务重新调度执行时再次加载进来，这样就能保证任务的原来状态不受影响，让任务看起来是连续运行的。

- CPU的上下文切换又分为进程上下文切换，线程上下文切换以及中断上下文切换。过多的上下文切换也是导致CPU出现性能瓶颈的原因。

  ``` shell
  [root@VM-0-10-centos ~]# vmstat
  procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
   r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
   3  0      0  84592  11812 193752    0    0    80    26   32  118  1  1 98  0  0
  
  # 
  # r (Runing or Runnable) 就绪队列的长度，也就是正在运行和等待CPU的进程数。
  # b (Blocked) 阻塞状态的进程数
  #
  # ============swap 域===============
  # si (swap in) 
  # so (swap out)
  #	使用交换分区不见得是坏事情，所以交换分区使用率不是什么严重的参数，但是频繁的 swap in/out 就不是好事情了，这种情况需要注意，通常表示物理内存紧缺的情况。
  # 
  # ============io 域=============
  # bi 表明每秒钟向磁盘接收的块数目(blocks/s)
  # bo 表明每秒钟向磁盘发送的块数目(blocks/s)
  #
  # ============system 域============
  # cs (context switch) 每秒的上下文切换次数
  # in (interrupt) 每秒的中断次数
  
  
  # pidstat 可以看到具体的某个应用程序的上下文切换情况
  # -t: 可以将进程中各个线程的详细信息罗列出来。
  # -r: 显示缺页错误和内存使用状况，缺页错误是程序需要访问映射在虚拟内存空间中但是还尚未被加载到物理内存中的一个分页。
  # -s: 栈使用状况，包括 StkSize 为线程保留的栈空间，以及 StkRef 实际使用的栈空间。
  # -u: CPU使用率情况。
  # -w: 线程上下文切换的数目。
  # -l: 可以显示完整的程序名和参数。
  # -C: 指定某个字符串，然后Command中如果包含这个字符串，那么该程序的信息就会被打印统计出来，起到筛选的作用。
  
  ubuntu@VM-16-9-ubuntu:~$ pidstat -w -t -C "system" -l
  Linux 4.15.0-142-generic (VM-16-9-ubuntu) 	11/21/2021 	_x86_64_	(2 CPU)
  
  02:31:46 PM   UID      TGID       TID   cswch/s nvcswch/s  Command
  02:31:46 PM     0       441         -      0.12      0.01  /lib/systemd/systemd-journald
  02:31:46 PM     0         -       441      0.12      0.01  |__/lib/systemd/systemd-journald
  02:31:46 PM     0       467         -      0.03      0.03  /lib/systemd/systemd-udevd
  02:31:46 PM     0         -       467      0.03      0.03  |__/lib/systemd/systemd-udevd
  02:31:46 PM   100       907         -      0.01      0.00  /lib/systemd/systemd-networkd
  # cswch (voluntary context switches) 自愿上下文切换，指的是进程无法获得所需的资源导致的上下文切换。比如I/O不足，内存不足。
  # nvcswch (non voluntary context switches) 非自愿上下文切换，指的是 进程由于时间片已到等原因，被系统强制调度，进而发生上下文切换。
  
  ubuntu@VM-16-9-ubuntu:~$ pidstat -r -C "system" -l
  Linux 4.15.0-142-generic (VM-16-9-ubuntu) 	11/21/2021 	_x86_64_	(2 CPU)
  
  02:38:40 PM   UID       PID  minflt/s  majflt/s     VSZ     RSS   %MEM  Command
  02:38:40 PM     0       441      0.98      0.00   90120   22972   0.59  /lib/systemd/systemd-journald
  02:38:40 PM     0       467      0.46      0.00   34936    4076   0.11  /lib/systemd/systemd-udevd
  02:38:40 PM   100       907      0.01      0.00   80964    5312   0.14  /lib/systemd/systemd-networkd
  02:38:40 PM   101       930      0.01      0.00   71660    6032   0.16  /lib/systemd/systemd-resolved
  
  # minflt/s 指的 minor faults，当需要访问的物理页面因为某些原因(比如共享页面、缓存机制等)已经存在于物理内存中了，只是在当前进程的页表中没有引用，MMU 只需要设置对应的 entry 就可以了，这个代价是相当小的
  # majflt/s 指的 major faults，MMU 需要在当前可用物理内存中申请一块空闲的物理页面(如果没有可用的空闲页面，则需要将别的物理页面切换到交换空间去以释放得到空闲物理页面)，然后从外部加载数据到该物理页面中，并设置好对应的 entry，这个代价是相当高的，和前者有几个数据级的差异
  ```
  
  
  

# 内存

## 概念

> 内存是计算机中重要的部件之一，它是与CPU进行沟通的桥梁。计算机中所有程序的运行都是在内存中进行的，因此内存的性能对计算机的影响非常大。
> 内存(Memory)也被称为内存储器，其作用是用于暂时存放CPU中的运算数据，以及与硬盘等外部存储器交换的数据。

- **物理内存** 指通过物理内存条而获得的内存空间。即随机存取存储器（random access memory，RAM），是与CPU直接交换数据的内部存储器，也叫主存(内存)。
- **虚拟内存** 是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。
- **Swap分区** 在系统的物理内存不够用的时候，把硬盘内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的硬盘空间就是swap分区，通常用来临时保存一些不活跃的运行程序，当需要运行时，再从swap读到内存中去。

``` shell
[root@VM-0-10-centos ~]# free -m   # 以M为单位显示结果
              total        used        free      shared  buff/cache   available
Mem:           1837        1554          74           1         208         134
Swap:             0           0           0

# 参数说明：
#   -m 表示结果单位是 MB
#   -k 表示结果单位是 KB
#   -g 表示结果单位是 GB
#   -h 表示以合适的单位显示结果数据

# total: 所有物理内存。total = used + free + shared + buff/cache
# used: 已被分配的内存。
# free: 未被分配的内存，真实的剩余物理内存。
# shared: 共享内存。基本用不到。
# buff/cache: 缓冲/缓存。缓冲：内存->磁盘；缓存：磁盘->内存。目的都是为了减少IO次数，提高IO性能。
# available: 还能被应用程序分配的内存，其中包含了一些buff/cache内存空间。

# 现在buffers和cached Mem信息总和到一起，通过对比数据，这两个值就是 /proc/meminfo 中的 Buffers 和 Cached 字段：Buffers 是针对 raw disk 的块缓存，主要是以 raw block 的方式缓存文件系统的元数据(比如超级块信息等)，这个值一般比较小(20M左右)；而 Cached 是针对于某些具体的文件进行读缓存，以增加文件的访问效率而使用的，可以说是用于文件系统中文件缓存使用。
```

``` shell
[root@VM-0-10-centos ~]# top  # 持续统计CPU和内存信息
top - 17:19:36 up 1 day, 23:55,  1 user,  load average: 0.06, 0.09, 0.07
Tasks: 113 total,   1 running, 112 sleeping,   0 stopped,   0 zombie
%Cpu(s):  1.0 us,  1.0 sy,  0.0 ni, 97.7 id,  0.3 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem :  1882016 total,    81996 free,  1592476 used,   207544 buff/cache  
KiB Swap:        0 total,        0 free,        0 used.   136492 avail Mem
```

```shell
root@VM-16-9-ubuntu:/etc/default# sar -W  # 查看分区统计信息
Linux 4.15.0-142-generic (VM-16-9-ubuntu) 	11/22/2021 	_x86_64_	(2 CPU)

11:04:10     LINUX RESTART	(2 CPU)

11:05:01 AM  pswpin/s pswpout/s
11:15:01 AM      0.00      0.00
11:25:01 AM      0.00      0.00
11:35:01 AM      0.00      0.00
Average:         0.00      0.00

# pswpin/s  换入，每秒从 swap 到 内存 的交换页面（swap page）的数量
# pswpott/s 换出，每秒从 内存 到 swap 的交换页面（swap page）的数量
```



## OOM

- **内存溢出 out of memory :**

  指程序要求的内存超出了系统所能分配的范围，出现out of memory；比如申请一个int类型，但给了它一个long才能存放的数，就会出现内存溢出，或者是创建一个大的对象，而堆内存放不下这个对象，这也是内存溢出。

- **内存泄露 memory leak :**

  是指程序在申请内存后，无法释放已申请的内存空间(<font color='red'>指分配出去的内存无法被gc回收</font>)。一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存，迟早会被占光。

　以上可以推断出内存泄露可能会导致内存溢出。内存溢出会抛出**OOM**异常，内存泄露不会抛出异常，此时程序看起来是正常运行的。



## 内存管理

**排查进程占用内存的情况：**

推荐工具：ps_mem

```shell
root@algoteam-nvidiaT4-dev:~ # ps_mem -h
ps_mem.py - Show process memory usage

-h                                 Show this help
-w <N>                             Measure and show process memory every N seconds
-p <pid>[,pid2,...pidN]            Only show memory usage PIDs in the specified list
-s, --show-cmdline                 Show complete program path with options
```

该工具不是linux自带工具，使用时需安装。

```shell
root@algoteam-nvidiaT4-dev:~ # ps_mem -s
 Private  +   Shared  =  RAM usedProgram 

 68.0 KiB +  35.0 KiB = 103.0 KiBrunsv monitor-addresses
 72.0 KiB +  35.0 KiB = 107.0 KiBrunsv allocate-tunnel-addrs
 72.0 KiB +  35.0 KiB = 107.0 KiBrunsv bird6
 72.0 KiB +  35.0 KiB = 107.0 KiBrunsv confd
 72.0 KiB +  35.0 KiB = 107.0 KiBrunsv bird
 72.0 KiB +  35.0 KiB = 107.0 KiBrunsv node-status-reporter
 72.0 KiB +  35.0 KiB = 107.0 KiBrunsv felix
 76.0 KiB +  35.0 KiB = 111.0 KiBrunsv cni
104.0 KiB +  39.0 KiB = 143.0 KiB/usr/local/bin/runsvdir -P /etc/service/enabled
128.0 KiB +  40.5 KiB = 168.5 KiB/sbin/agetty --keep-baud 115200,38400,9600 ttyS0 vt220
```



**清理buffer/cache：**

```shell
# sync命令以确保文件系统的完整性，sync 命令运行 sync 子进程，将所有未落盘的系统缓冲写到磁盘中，包含已修改的 i-node、已延迟的块 I/O 和读写映射文件。
linux-8v2i:~ # sync  

# 修改/proc/sys/vm/drop_caches
echo 3 > /proc/sys/vm/drop_caches

说明：
1. /proc是一个虚拟文件系统，我们可以通过对它的读写操作作为与kernel实体间进行通信的一种手段。也就是说可以通过修改/proc中的文件，来对当前kernel的行为做出调整。也就是说我们可以通过调整/proc/sys/vm/drop_caches来释放内存。
2. 关于drop_caches的官方说明如下：
Writing to this file causes the kernel to drop clean caches,dentries and inodes from memory, causing that memory to becomefree. 

To free pagecache, use echo 1 > /proc/sys/vm/drop_caches;
to free dentries and inodes, use echo 2 > /proc/sys/vm/drop_caches; 
to free pagecache, dentries and inodes, use echo 3 >/proc/sys/vm/drop_caches. 

Because this is a non-destructive operation and dirty objects are not freeable, the user should run sync first.
 
3. Linux内核会将它最近访问过的文件页面缓存在内存中一段时间，这个文件缓存被称为pagecache。
```



## 内存统计

- **VSS**

  Virtual Set Size。进程申请分配的内存量，例如进程多次调用 malloc 申请了多块内存空间，他们的体积之和就是VSS。

- **RSS**

  Resident Set Size。进程长期驻留的内存量，也就是进程实际使用的内存。

  - 假设进程 A 申请分配了 10MB 内存空间，实际只在 2MB 内存空间中写入了数据。则 VSS 为 10MB ， RSS 为 2MB 。

  - 如果进程释放一些已用内存，则统计的 RSS 不会减少。因此 RSS 可能比进程实际占用的内存虚高。
    RSS = 进程独占的非共享内存 + SHR。

    - RSS 包括堆、栈、共享内存，不包括 Swap ，也不包括 page tables、huge page、kernel stack、struct thread_info、struct task_struct 等。

    - 用如下命令可统计所有进程的 RSS 内存之和，但这样会重复累计 SHR 内存，因此计算结果比所有进程实际占用的内存量虚高。为了减少误差，应该统计所有进程的 PSS 内存之和。

      ```shell
      ps -eo rss | awk 'NR>1' | awk '{sum+=$1} END {print sum/1024}'
      ```

- **SHR**

  Shared Memory。进程占用的共享内存，例如多个进程可能导入同一个共享库 glibc。

- **PSS**

  Proportional Set Size。按比例估算出进程的常驻内存。

  - PSS = 进程独占的非共享内存 + 进程平均占用的 SHR
  - 假设进程 A 的 RSS 为 10MB ，其中 8MB 为非共享内存，2MB 为与其它 N 个进程共享的内存。则进程 A 的 PSS = 8 + 2/(N+1) MB 。

- **WSS**

  Working Set Size。进程保持工作所需的内存。是估算进程最近访问过的 Pages 数，包括物理内存、内核内存、脏页。

  wss可以约等于 RSS + active_file。

  - Linux系统会把进程占用后多余的内存用作page cache，当访问文件后就加载到内存中，加速后面再次访问文件的速度。当系统需要更多常驻内存的时候，又会从page cache腾出空间分给常驻内存。这种用途的内存叫做 file-backed memory（相对应与文件无关的叫anonymous memory）
  - page cache分为 inactive_file 和 active_file。第一次读写文件后的cache，属于inactive_file，多次访问这个文件之后，属于active_file。inactive_file的cache是会可以被操作系统直接回收使用的，active_file不会直接回收，而是先变成inactive_file
  - 容器内存通常满足 rss + active_file + inactive_file < memory limit
  - 申请常驻内存是，并不是先把inactive_file先回收完才回收active_file部分的，而是随着inactive_file减少，部分active_file会变成inactive_file，两者维持一定的比例
  - 最后所有cache已经回收完了，内存不够分配，容器发生OOMKilled





# 网络

## ping

ping 命令，检查网络连通性。

```shell
zhangjian@zhangjiandeMacBook-Pro ~ % ping 101.43.61.175
PING 101.43.61.175 (101.43.61.175): 56 data bytes
64 bytes from 101.43.61.175: icmp_seq=0 ttl=51 time=47.883 ms
64 bytes from 101.43.61.175: icmp_seq=1 ttl=51 time=52.132 ms
64 bytes from 101.43.61.175: icmp_seq=2 ttl=51 time=54.960 ms
64 bytes from 101.43.61.175: icmp_seq=3 ttl=51 time=45.531 ms
...
--- 101.43.61.175 ping statistics ---
27 packets transmitted, 27 packets received, 0.0% packet loss
round-trip min/avg/max/stddev = 43.573/52.471/69.857/4.886 ms

# time: 显示了两台主机之间的网络延时情况，如果此值很大，表示网络延迟很大。
# packet loss: 表示网络丢包率，该值越小，表示网络的质量越高。
```



## netstat

> -a (all)显示所有选项，默认不显示LISTEN相关
>
> -t (tcp)仅显示tcp相关选项
>
> -u (udp)仅显示udp相关选项
>
> -n 拒绝显示别名，能显示数字的全部转化成数字
>
> -l 仅列出有在 Listen (监听) 的服務状态
>
> -p 显示建立相关链接的程序名
>
> -r 显示路由信息，路由表
>
> -e 显示扩展信息，例如uid等
>
> -s 按各个协议进行统计
>
> -c 每隔一个固定时间，执行该netstat命令
>
> -i 显示网络界面信息表单
>
> 提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到



```shell
# 检查网络设备状况 netstat -i
ubuntu@VM-16-9-ubuntu:~$ netstat -i
Kernel Interface table
Iface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg
docker0   1500        0      0      0 0             0      0      0      0 BMU
eth0      1500   451310      0      0 0        420093      0      0      0 BMRU
lo       65536    28748      0      0 0         28748      0      0      0 LRU

# Iface: 表示网络设备的接口名称
# MTU: 表示最大传输单元，单位字节
# RX-OK/TX-OK: 表示已经准确无误地接收/发送了多少数据包
# RX-ERR/TX-ERR: 表示接收/发送数据包时产生了多少错误
# RX-DRP/TX-DRP: 表示接收/发送数据包时丢弃了多少数据包
# RX-OVR/TX-OVR: 表示由于误差而遗失了多少数据包
# Flg: 表示接口标记，其中：
#		L: 表示该接口是个回环设备
#		B: 表示设置了广播地址
#		M: 表示接收所有数据包
#		R: 表示接口正在运行
#		U: 表示接口处于活动状态
#		0: 表示在该接口上禁用ARP
#		P: 表示一个点到点的连接

正常情况下，RX-ERR/TX-ERR、RX-DRP/TX-DRP、RX-OVR/TX-OVR的值都应该为0，如果这几个选项的值不为0，并且很大，那么网络质量肯定有问题，网络传输性能也一定会下降。

当网络传输存在问题时，可以检测网卡设备是否存在故障，如果可能，可以升级为千兆网卡或者光纤网络，还可以检查网络部署环境是否合理。

# 查看网络端口相关信息netstat -anp
[root@vcm-vcm-deployment-6dd5f5666-28gmj vcm]# netstat -anp
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 10.49.8.139:38016       10.49.24.209:9000       TIME_WAIT   -                   
tcp        0      0 127.0.0.1:59678         127.0.0.1:38091         ESTABLISHED -                   
tcp6       0      0 :::38091                :::*                    LISTEN      -                   
tcp6       0      0 :::38093                :::*                    LISTEN      -                   
tcp6       0      0 10.49.8.139:38091       10.49.8.1:59348         TIME_WAIT   -                   
tcp6       0      0 10.49.8.139:38091       10.49.8.1:42200         TIME_WAIT   -                   
tcp6       0      0 10.49.8.139:38091       10.49.8.1:41042         TIME_WAIT   -                   
tcp6       0      0 10.49.8.139:38091       10.49.8.1:43712         TIME_WAIT   -                   
tcp6       0      0 127.0.0.1:38091         127.0.0.1:59678         ESTABLISHED -                   
tcp6       0      0 10.49.8.139:38091       10.49.8.1:38718         TIME_WAIT   -                   
tcp6       0      0 10.49.8.139:38091       10.49.8.1:37150         TIME_WAIT   -                   
tcp6       0      0 10.49.8.139:38091       10.49.8.1:39952         TIME_WAIT   -                   
tcp6       0      0 10.49.8.139:38091       10.49.8.1:34976         TIME_WAIT   -                   
tcp6       0      0 10.49.8.139:38091       10.49.8.1:44906         TIME_WAIT   -                   
tcp6       0      0 10.49.8.139:38091       10.49.8.1:60404         TIME_WAIT   -                   
tcp6       0      0 10.49.8.139:38091       10.49.8.1:36090         TIME_WAIT   -            
tcp6       0      0 10.49.8.139:38091       10.49.8.1:46022         TIME_WAIT   -           
udp        0      0 10.49.8.139:61000       0.0.0.0:*                           -    
```



## route

检查系统路由信息

```shell
ubuntu@VM-16-9-ubuntu:~$ route -n  # -n参数就是在输出的信息中不打印主机名而直接打印ip地址。
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.0.16.1       0.0.0.0         UG    100    0        0 eth0
10.0.16.0       0.0.0.0         255.255.252.0   U     0      0        0 eth0
172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0

# Destination 目标网络或目标主机
# Geteway 网关地址，没有就显示星号*
# Genmask 网络掩码
# Flags 路由标识，有以下几个常用的标识：
#		U — 该路由是启动的
#		H — 目标是一个主机而非网域
#	 	G — 需要透过外部的主机 (gateway) 来转递封包
# 	R — 使用动态路由时，恢复路由资讯的标识
# 	D — 已经由服务或转 port 功能设定为动态路由
# 	M — 路由已经被修改了
# 	! — 这个路由将不会被接受(用来抵挡不安全的网域！）
# Metric 距离、跳数。即到达目标网络需要中转的次数。linux内核暂未使用
# Ref   不用管，恒为0。linux内核暂未使用
# Use    该路由被使用的次数，可以粗略估计通向指定网络地址的网络流量
#	Iface 接口，即eth0,docker0等网络接口名
```



## sar

**sar –n组合显示系统网络运行状态**

sar -n选项使用6个不同的开关：DEV，EDEV，NFS，NFSD，SOCK，IP，EIP，ICMP，EICMP，TCP，ETCP，UDP，SOCK6，IP6，EIP6，ICMP6，EICMP6和UDP6 ，DEV显示网络接口信息，EDEV显示关于网络错误的统计数据，NFS统计活动的NFS客户端的信息，NFSD统计NFS服务器的信息，SOCK显示套接字信息，ALL显示所有5个开关。它们可以单独或者一起使用。 



```shell
ubuntu@VM-16-9-ubuntu:~$ sar -n TCP,ETCP 1 1  # 查看TCP包，每间隔1秒统计一次，总计统计1次
Linux 4.15.0-142-generic (VM-16-9-ubuntu) 	11/22/2021 	_x86_64_	(2 CPU)

10:34:25 AM  active/s passive/s    iseg/s    oseg/s
10:34:26 AM      0.00      0.00      2.00      0.00

10:34:25 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s
10:34:26 AM      0.00      0.00      0.00      0.00      0.00

Average:     active/s passive/s    iseg/s    oseg/s
Average:         0.00      0.00      2.00      0.00

Average:     atmptf/s  estres/s retrans/s isegerr/s   orsts/s
Average:         0.00      0.00      0.00      0.00      0.00

# active/s：本地发起的 TCP 连接，比如通过 connect()，TCP 的状态从CLOSED -> SYN-SENT
# passive/s：由远程发起的 TCP 连接，比如通过 accept()，TCP 的状态从LISTEN -> SYN-RCVD
# iseg/s 接受的数据段，数据段 是传输层的数据分组
# oseg/s 输出的数据段
# retrans/s(tcpRetransSegs)：每秒钟 TCP 重传数目，通常在网络质量差，或者服务器过载后丢包的情况下，根据 TCP 的确认重传机制会发生重传操作
# isegerr/s(tcpInErrs)：每秒钟接收到出错的数据包(比如 checksum 失败)
```



```shell
ubuntu@VM-16-9-ubuntu:~$ sar -n UDP 1 1
Linux 4.15.0-142-generic (VM-16-9-ubuntu) 	11/22/2021 	_x86_64_	(2 CPU)

10:38:03 AM    idgm/s    odgm/s  noport/s idgmerr/s
10:38:04 AM      0.00      0.00      0.00      0.00
Average:         0.00      0.00      0.00      0.00

# noport/s(udpNoPorts)：每秒钟接收到的但是却没有应用程序在指定目的端口的数据报个数
# idgmerr/s(udpInErrors)：除了上面原因之外的本机接收到但却无法派发的数据报个数
```



```shell
ubuntu@VM-16-9-ubuntu:~$ sar -n DEV 1 1 # 查看网络接口信息
Linux 4.15.0-142-generic (VM-16-9-ubuntu) 	11/22/2021 	_x86_64_	(2 CPU)

10:40:21 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
10:40:22 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
10:40:22 AM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
10:40:22 AM      eth0     14.00     12.00      1.21      1.69      0.00      0.00      0.00      0.00

Average:        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
Average:      docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
Average:           lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
Average:         eth0     14.00     12.00      1.21      1.69      0.00      0.00      0.00      0.00

# Iface:	表示网络设备的接口名称
# rxpck/s:	表示每秒钟接收的数据包大小
# txpck/s:	表示每秒钟发送的数据包大小
# rxbyt/s:	表示每秒钟接收的字节数
# txbyt/s:	表示每秒钟发送的字节数
# rxcmp/s:	表示每秒钟接收的压缩数据包
# txcmp/s:	表示每秒钟发送的压缩数据包
# rxmcst/s:	表示每秒钟接收的多播数据包
# %ifutil:	CPU占用比
```



## 查看端口详情

lsof -i:端口号

```shell
# lsof -i:8000
COMMAND   PID USER   FD   TYPE   DEVICE SIZE/OFF NODE NAME
nodejs  26993 root   10u  IPv4 37999514      0t0  TCP *:8000 (LISTEN)
```



netstat -tunlp | grep 端口号

```shell
# netstat -tunlp | grep 8000
tcp        0      0 0.0.0.0:8000            0.0.0.0:*               LISTEN      26993/nodejs  
```



# 磁盘

## df

df（英文全拼：disk free） 命令用于显示目前在 Linux 系统上的文件系统磁盘使用情况统计。

> 语法：
>
> ```
> df [选项]... [FILE]...
> ```
>
> 选项：
>
> - 文件-a, --all 包含所有的具有 0 Blocks 的文件系统
> - 文件--block-size={SIZE} 使用 {SIZE} 大小的 Blocks
> - 文件-h, --human-readable 使用人类可读的格式(预设值是不加这个选项的...)
> - 文件-H, --si 很像 -h, 但是用 1000 为单位而不是用 1024
> - 文件-i, --inodes 列出 inode 资讯，不列出已使用 block
> - 文件-k, --kilobytes 就像是 --block-size=1024
> - 文件-l, --local 限制列出的文件结构
> - 文件-m, --megabytes 就像 --block-size=1048576
> - 文件--no-sync 取得资讯前不 sync (预设值)
> - 文件-P, --portability 使用 POSIX 输出格式
> - 文件--sync 在取得资讯前 sync
> - 文件-t, --type=TYPE 限制列出文件系统的 TYPE
> - 文件-T, --print-type 显示文件系统的形式
> - 文件-x, --exclude-type=TYPE 限制列出文件系统不要显示 TYPE
> - 文件-v (忽略)
> - 文件--help 显示这个帮手并且离开
> - 文件--version 输出版本资讯并且离开

示例：

```shell
ubuntu@VM-16-9-ubuntu:~$ df -h
Filesystem      Size  Used Avail Use% Mounted on
udev            1.9G     0  1.9G   0% /dev
tmpfs           379M  6.4M  373M   2% /run
/dev/vda1        79G  3.1G   73G   5% /
tmpfs           1.9G   24K  1.9G   1% /dev/shm
tmpfs           5.0M     0  5.0M   0% /run/lock
tmpfs           1.9G     0  1.9G   0% /sys/fs/cgroup
tmpfs           379M     0  379M   0% /run/user/500
```



## du

du （英文全拼：disk usage）命令用于显示目录或文件的大小，du 会显示指定的目录或文件所占用的磁盘空间。

>语法：
>
>```
>du [选项] [目录或文件]
>```
>
>选项：
>
>- -a或-all 显示目录中所有文件的大小。
>- -b或-bytes 显示目录或文件大小时，以byte为单位。
>- -c或--total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。
>- -D或--dereference-args 显示指定符号连接的源文件大小。
>- -h或--human-readable 以K，M，G为单位，提高信息的可读性。
>- -H或--si 与-h参数相同，但是K，M，G是以1000为换算单位。
>- -k或--kilobytes 以1024 bytes为单位。
>- -l或--count-links 重复计算硬件连接的文件。
>- -L<符号连接>或--dereference<符号连接> 显示选项中所指定符号连接的源文件大小。
>- -m或--megabytes 以1MB为单位。
>- -s或--summarize 仅显示总计。
>- -S或--separate-dirs 显示个别目录的大小时，并不含其子目录的大小。
>- -x或--one-file-xystem 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。
>- -X<文件>或--exclude-from=<文件> 在<文件>指定目录或文件。
>- --exclude=<目录或文件> 略过指定的目录或文件。
>- --max-depth=<目录层数> 超过指定层数的目录后，予以忽略。
>- --help 显示帮助。
>- --version 显示版本信息。

示例：

```shell
# 查看当前目录下磁盘大文件，此时 du 后面没有接目标目录或文件，则默认统计当前路径
$ du -ah|grep 'M'|sort -rn|head -n 30
986M    ./jenkins/workspace/application-data/volumes/data_platform/dataservice/data/diag_simi_service/Word2Vec_Model
984M    ./jenkins/workspace/application-data/volumes/elk/es
984M    ./jenkins/workspace/application-data/volumes/elk
950M    ./jenkins/workspace/application-data/volumes/elk/es/data/nodes/0/indices

# 查看当前目录下文件的大小，包括文件夹
SeekerdeMacBook-Pro:modelTgz zhangjian1138$ du -sh *
528M    model_B
 58M    rnn_rebuildVector.tar.gz
 57M    test_detail_rnn.tar.gz
470M    test_model_B.tar.gz
368M    test_model_B.tar.xz
137M    test_model_C.tar.gz
```



## iostat

iostat是I/O statistics（输入/输出统计）的缩写，iostat工具将对系统的磁盘操作活动进行监视。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况。iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。

**语法：**

```shell
iostat [选项] [<时间间隔>] [<次数>]

# 选项参数
-c： 显示CPU使用情况
-d： 显示磁盘使用情况
-N： 显示磁盘阵列(LVM) 信息
-n： 显示 NFS 使用情况。NFS 是指网络文件系统，能使计算机访问别的计算机中的文件，就像访问自己的一样。
-k： 以 KB 为单位显示
-m： 以 M 为单位显示
-t： 报告每秒向终端读取和写入的字符数和CPU的信息
-V： 显示版本信息
-x： 显示详细信息
-p：[磁盘] 显示磁盘和分区的情况
```

**示例一：**

```shell
# 显示所有的设备负载情况
ubuntu@VM-16-9-ubuntu:~$ iostat
Linux 4.15.0-142-generic (VM-16-9-ubuntu) 	11/21/2021 	_x86_64_	(2 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.35    0.01    0.34    0.02    0.00   99.28

Device             tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
loop0             0.00         0.00         0.00          1          0
scd0              0.01         0.16         0.00       8324          0
vda               2.36        11.23        40.10     594899    2124905

# device:磁盘名称
# tps:每秒钟发送到的I/O请求数.
# kB_read/s:每秒读取数据.
# kB_wrtn/s:每秒写入数据.
# kB_read:读入的数据总量.
# kB_wrtn:写入的数据总量.
```

**示例二：**

```shell
ubuntu@VM-16-9-ubuntu:~$ iostat -d -x -k 1 1
Linux 4.15.0-142-generic (VM-16-9-ubuntu) 	11/21/2021 	_x86_64_	(2 CPU)

Device            r/s     w/s     rkB/s     wkB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
loop0            0.00    0.00      0.00      0.00     0.00     0.00   0.00   0.00    0.00    0.00   0.00     1.00     0.00   0.00   0.00
scd0             0.01    0.00      0.16      0.00     0.00     0.00   0.00   0.00    0.27    0.00   0.00    21.29     0.00   0.27   0.00
vda              0.37    1.98     11.10     39.80     0.00     1.72   0.00  46.36    0.71    0.73   0.00    30.14    20.06   0.07   0.02

# r/s: 每秒完成的读 I/O 设备次数。即 rio/s
# w/s: 每秒完成的写 I/O 设备次数。即 wio/s
# ========这里没有=======
# rsec/s: 每秒读扇区数。即 rsect/s
# wsec/s: 每秒写扇区数。即 wsect/s
# ========这里没有=======
# rkB/s: 每秒读K字节数。是 rsect/s 的一半，因为每扇区大小为512字节。
# wkB/s: 每秒写K字节数。是 wsect/s 的一半。
# rrqm/s: 每秒进行 merge 的读操作数目。即 rmerge/s
# wrqm/s: 每秒进行 merge 的写操作数目。即 wmerge/s
# r_await: 每个读操作平均所需的时间，不仅包括硬盘设备读操作的时间，还包括了在kernel队列中等待的时间。
# w_await: 每个写操作平均所需的时间，不仅包括硬盘设备写操作的时间，还包括了在kernel队列中等待的时间。
# await: 平均每次设备I/O操作的等待时间 (毫秒)。
# svctm: 平均每次设备I/O操作的服务时间 (毫秒)。
# %util: 一秒中有百分之多少的时间用于 I/O 操作，即被io消耗的cpu百分比

# 备注：如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明I/O 队列太长，io响应太慢，则需要进行必要优化。如果avgqu-sz比较大，也表示有当量io在等待。
```



## sar

```shell
root@VM-16-9-ubuntu:/etc/default# sar -d -p 1 1
Linux 4.15.0-142-generic (VM-16-9-ubuntu) 	11/22/2021 	_x86_64_	(2 CPU)

11:20:34 AM       DEV       tps     rkB/s     wkB/s   areq-sz    aqu-sz     await     svctm     %util
11:20:35 AM     loop0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
11:20:35 AM       sr0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
11:20:35 AM       vda     59.00      0.00    256.00      4.34      0.03      0.54      0.07      0.40

Average:          DEV       tps     rkB/s     wkB/s   areq-sz    aqu-sz     await     svctm     %util
Average:        loop0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
Average:          sr0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
Average:          vda     59.00      0.00    256.00      4.34      0.03      0.54      0.07      0.40

# DEV 磁盘设备的名称，如果不加-p，会显示dev253-0类似的设备名称，因此加上-p显示的名称更直接
# tps：每秒I/O的传输总数
# rd_sec/s 每秒读取的扇区的总数
# wr_sec/s 每秒写入的扇区的总数
# areq-sz 平均每次次磁盘I/O操作的数据大小（扇区）
# aqu-sz 磁盘请求队列的平均长度
# await 从请求磁盘操作到系统完成处理，每次请求的平均消耗时间，包括请求队列等待时间，单位是毫秒（1秒等于1000毫秒），等于寻道时间+队列时间+服务时间
# svctm I/O的服务处理时间，即不包括请求队列中的时间
# %util I/O请求占用的CPU百分比，值越高，说明I/O越慢
```

```shell
root@VM-16-9-ubuntu:/etc/default# sar -b
Linux 4.15.0-142-generic (VM-16-9-ubuntu) 	11/22/2021 	_x86_64_	(2 CPU)

11:04:10     LINUX RESTART	(2 CPU)

11:05:01 AM       tps      rtps      wtps   bread/s   bwrtn/s
11:15:01 AM      1.86      0.00      1.86      0.00     27.71
11:25:01 AM      1.94      0.00      1.94      0.00     28.59
Average:         1.90      0.00      1.90      0.00     28.15

#	tps 磁盘每秒钟的IO总数，等于iostat中的tps
#	rtps 每秒钟从磁盘读取的IO总数
#	wtps 每秒钟从写入到磁盘的IO总数
#	bread/s 每秒钟从磁盘读取的块总数
# bwrtn/s 每秒钟此写入到磁盘的块总数
```









