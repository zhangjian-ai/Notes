## 软件生命周期

计划阶段（planning）=> 需求分析（requirement）=> 设计阶段（design）=> 编码（coding）=> 测试（testing）=> 运行与维护（running maintrnacne）



## 性能问题定位

功能测试时，接口链路追踪：

1. Jaeger 链路追踪，查看接口调用详情。可以看到 后端服务调用耗时、IO阻塞耗时等。
2. 如果是RPC接口调用耗时高，那么就要排查被调服务状态。通过grafana监控信息查看该服务CPU、内存、网络IO、磁盘IO等监控数据是否正常，如果被调用的服务，请求队列长期处于排队状态，则需要考虑扩展被调方服务。
3. 如果是IO阻塞耗时较多，比如数据库操作，则需要分析数据库压力是否过大或着SQL本身存在性能瓶颈。



性能测试时，性能分析：

1. 不同的接口，由于后端调用链路复杂度不同，因此不同的接口，承载的峰值QPS也是不同的。

2. grafana分析JVM堆栈信息（used：已使用的空间；committed：已经向linux内核申请的空间），检查是否正常。如果正常响应时间还很长，那么要考虑服务内部的服务调用和IO阻塞等问题。

   >Xmx：最小堆内存
   >
   >Xms：最大堆内存

3. 单个服务峰值QPS在100～200之间，目前后端部署了12个结点，最大峰值能承受2000QPS左右。



## 测试管理流程

测试管理过程是一个从开始到结束管理软件测试活动的过程。测试管理过程在整个项目周期中提供计划、控制、跟踪和监控设施。这个过程涉及几个活动，如测试计划、设计和测试执行。它为软件测试过程提供了一个初步计划和规范。

测试管理过程有两个主要部分：**计划、执行**

- **计划**

    1. 风险分析

        风险分析是测试经理在任何项目开始前应该要首先考虑的。尽早的识别出项目的潜在风险、对已有功能的影响等。提早制定对策，最大程度的降低风险带来的负面影响。

    2. 测试评估

        测试评估是大致确定一项任务需要多长时间完成，估算测试的工作量。准确的测试估计能使测试经理关注的任务得到更好的计划、执行和监控；同时允许更准确的调度，帮助更有信心地实现结果。

    3. 测试计划

        测试计划可以被定义为描述测试活动的范围、方法、资源和时间表的文件。

        - 测试策略：明确用例设计方法：等价类、边界值、异常流程构建等；明确测试方法：手工测试、自动化冒烟覆盖测试等
        - 测试目标：要测试的功能模块是什么，以及该功能的上下游关联逻辑的有哪些，哪些重点覆盖，哪些过主流程
        - 退出/暂停标准：功能点覆盖100%，高中优先级缺陷全部修复，低优修复率 95%
        - 资源规划：多少人多少时间的投入
        - 测试交付件：测试完成后要提供的交付件，比如 用例集、功能测试报告、缺陷列表 等

    4. 测试组织

        测试组织主要是由测试经理来安排并分配测试任务，使项目中各个任务都可以在计划内顺利完成。

        需求分配遵循四个原则：

        1. 压力分散。工作量、需求难易程度 尽量均匀
        2. 业务覆盖。测试成员应尽量全面的参与到产品的每个功能的测试上来
        3. 业务能手。对于核心业务流程，重点培养业务专家，有专项能力支持
        4. 资源预留。从人力、时间上都要保存一定的余量，以应对紧急问题和潜在风险

- **执行**

    1. 过程监督

        测试过程主要有四步：需求梳理、用例输出评审、测试执行、缺陷回归

        监测测试进展是否符合预期，有无推进上的阻塞，如果存在需要及时介入。监测的指标主要是 用例执行百分比、待修复缺陷数量等。

    2. 风险管理

        除开 测试验证、缺陷修复、回归验证 等常规的活动开展以外。测试经理必须要识别过程中的风险，并能够有效的处理风险。

        比如因开发延迟提测，挤压测试时间而无法如期完成时，可以通过 人力借调、测试范围缩减、项目延期评估 等多种方式来处理。

    3. 测试评估

        整理测试交付件，并对当前交付做出质量评估。在质量分析过程中，针对 重要的核心需求，要认真分析测试的广度和深度（测试粒度是否够细、是否要压力测试 等），同时 根据缺陷的分布情况，对缺陷较多的部分，在必要时组织深耕测试。



## 测试leader的职责

1. 提前规划。短期、中长期的里程碑目标，大致的需求范围
2. 需求把控。要计划纳入迭代的需求是否满足DOR，分析潜在风险，提前制定对策
3. 测试管理。上一个问题中，测试经理的工作内容
4. 生产监控。安排值周人员，及时处理线上问题，监测生产环境各项指标
5. 及时激励。制定奖惩机制，多鼓励内部成员，针对表现突出的同学及时给予肯定和激励，提升员工在团队内部的荣誉感
6. 人员稳定。与成员保持友好沟通，关注员工的精神状态，及时调整开导，提升员工在团队内部的幸福感
7. 能力提升。包括业务和技术的双线提升。通过老带新、师带徒等方式，让员工在业务上有所提升；在完成业务工作的同时，组织团队内部知识分享，包括但不限于测试方法论、测试相关工具的使用、自动化测试编程等，让员工在技术上有所成长。在使员工有所收获、有所提升的同时，提高业务测试效率，沉淀团队资产。



## 研发项目管理内容

对外管理原则：目标对齐、提前规划、风险分析、需求把控、结果反馈

对内管理原则：制定目标、监督过程、量化结果、及时激励、人员稳定、共同成长

具体实施：基于敏捷开发思想，是一个标准的 Scrum 开发框架下的持续迭代过程

绩效考核：上线质量、专业&敬业、协作&成长、创新&改进



## 测试如何驱动开发

1. 同上级leader和同级团队意识上达成一致，那就是交付质量的重要性。返工带来的成本开销、客户口碑都是成倍的得不偿失。

2. 测试的定位，除开本职的测试工作外，测试更能起到一个润滑剂的作用，比产品更懂逻辑实现，比开发更懂产品交互。因此，测试同学本身的owner意识很重要，要更为主动的去推进。

    通过需求完成情况、上线BUG数、问题响应速度、团队贡献等方面，进行绩效考核；对表现好的同学及时激励。通过这两种方式，来保持测试同学的主动性和积极性。

3. 测试左移，需要投入成本。测试介入 代码review、单元测试、接口测试 ，尽可能早的暴露问题

4. 测试本身能力加强，测试驱动开发，想要形成比较好的生态，那测试的介入及推动，要能够切实的解决问题，让产品、开发有感。

    这就至少要求测试对产品业务和实现逻辑都有充分的了解；进阶要有清晰的问题分析思路；在最后就是能准确定位到问题，不一定是说哪一行代码实现有问题，至少是某个接口的逻辑有问题（通过日志排查，数据库数据校对）

5. 立足产品，要求测试充分理解需求，有理有据的推进需求，能够从业务上充分说服开发，根据当前实现逻辑说服产品



## 测试如何保证质量

首先要说明一点，保证产品的质量，是需要整个产研全员参与的，规范的质量控制需要专职的QA来监督、跟踪整个软件研发周期各个阶段的质量。

先说一说测试介入之前的质量管理：

1. 需求质量。需要产品经理认真、全面的调研，输出具有缜密的逻辑和可行性需求文档，同时在需求评审阶段，敲定需求最终方案。
2. 开发设计。开发设计文档评审，确认需求的实现逻辑是否正确，以及从可靠性、扩展性方面思考可能潜在的问题。
3. 代码质量。要求开发做好代码的走读、review以及单元测试。测试左移（单元测试、接口测试）在编码阶段保证质量。
4. 文档质量。阶段性输出的文档、报告需要满足下一阶段的入口标准，需求提测时，要求开发先完成自测且满足提测标准。重点是接口文档。



测试介入时的质量管理：

1. 测试策略方面：质量是多维度的，从 功能、性能、可靠性、易用性、兼容性 等多个角度进行测试，覆盖的维度越多，那么交付产品的质量必然更高，当然，也需要花费更多的时间和人力。
2. 测试用例方面：从正向用例、异常场景角度设计用例，同时关注模块上下游逻辑，新功能影响面等方向设计用例，并通过全员用例评审，多角度补全用例覆盖面。
3. 测试执行方面：严格以需求为依据，展开用例执行，重点功能交叉执行覆盖。
4. 缺陷管理方面：保证BUG管理流程的规范，对BUG本身以及影响点的覆盖回归。
5. 测试报告方面：全局分析测试报告，梳理BUG分布的集中点，必要时针对BUG集中分布的模块在进行一轮深耕测试。
6. 上线验证方面：采取内测机制，邀请用户参与产品内测，从真实用户角度对产品进行测试优化。
7. 生产环境方面：进行灰度发布，需要持续跟踪线上产品状态，一旦出现质量问题，能够及时响应处理，将负面影响降到最低。



## 接口测试的意义

**1. 什么是接口测试**

​		是针对被测系统和外部系统之间、被测系统内部各模块间的接口的一种测试。

​		测试的重点是测试 **接口参数传递的正确性、接口功能实现的完备性、以及对各种容错处理的合理性和准确性。**



**2.为什么做接口测试**

- 测试前置，尽早暴露问题

  - 接口测试不依赖前端的开发进度，服务端设计出接口文档就可以着手测试工作，需求阶段我们就可以做出测试计划，配置测试环境，每提交一个接口就可以进行测试。接口测试的目标就是在前端测试开始前完成所有接口测试，这样可以尽早的抛出问题，节约测试时间

- 降低成本，提高测试效率

  - 接口测试更接近底层，大量的计算、逻辑处理都在服务端，接口测试更容易发现底层问题，根据数据模型推算，底层一个bug能购引起上层8个左右bug， 由此可以节省更多开发测试时间
  - 接口测试相比于UI，实现自动化持续集成的成本更低。首次准备好测试用例之后，后续的回归都可以直接使用自动化回归
  - 接口测试对服务器环境的依赖度低，甚至可以本地起一个服务，完成接口测试

- 测试结果更加可靠

  - 接口测试的粒度比功能测试更小，可以覆盖功能测试覆盖不到的测试点。因为很多时候，前端JS也会对数据的合法性进行检查，单纯的功能测试，有时候往往覆盖的面不够全




## 自动化框架设计

已经有Jmeter、Postman 等开源接口测试工具，为什么还要自己开发接口自动化测试框架？

> Jmeter 可以做接口测试，但是对于大量的接口用例维护以及前后接口关联的场景，维护的成本很高。而Jmeter支持的各种监控指标，并发模拟更适合用作性能测试；
>
> Postman 则是相对简单的一个接口调用工具，不适合做持续集成、定时任务等。

1. 主要原因是开源工具具有通用性，针对复杂业务流程的测试很乏力；
2. 开源工具、框架，通常需要测试人员花费较多的时间去学习和使用，并对代码能力有一定要求，推广起来存在困难；
3. 开源工具很难进行版本和分支的管理，维护成本高；
4. 测试报告单一，仅有一些通用指标，无法统计业务相关的指标；
5. 测试用例通常不是标准化的，不同成员间风格各异，从长期迭代维护来看，后续修改更新成本高；



**测试框架应具备的能力：**

1. **动态测试数据**  动态生成各种测试数据，特别是业务相关的测试数据，使得测试更接近真实使用场景；
2. **更小粒度的参数化**  可以轻松实现用例级别、测试步骤（单个接口）级别的参数化，减少脚本编写和维护的工作量；
3. **步骤级别的重试**  针对大多数场景，流程数据的变化往往存在延时。可以轻松实现单接口的多次断言；
4. **更灵活的数据关联**  可以缓存同一接口多次请求的返回值，后续接口可轻松获取用例任一接口的返回信息；
5. **用例结构标准化**  不依赖测试的代码能力，按照标准化的配置，通过编写配置文件即可实现自动化用例；
6. **版本维护灵活**  使用标签标记特殊用例，测试脚本可按需执行，而不需要向传统工具那样硬区分；
7. **断言的有效性**  可以轻松实现堆json数据结构，多个KV及多层级的KV实现断言，且可动态生成断言的预期结果；
8. **定制化测试报告**  可以根据实际需求采集接口调用各个阶段的日志、用例描述信息等；



## 自动化测试收益

​		自动化测试是希望能够通过自动化测试工具或其他手段，按照测试工程师的预定计划进行自动的测试。目标是减轻手工测试的劳动量，让更多的人力和时间用在新迭代的需求和模块上，从而保证产品质量、提高测试效率。

​		自动化测试的目的在于 **发现原有模块引入的新缺陷、保证现有功能的质量、降低测试人员在回归测试上的成本开销。**为了提高自动化测试的收益，那么需要 用例覆盖范围尽可能的广、功能点测试粒度尽可能的细、执行频率尽可能的高 等。

​		有人质疑，自动化测试是否能保证产品质量，其实自动化仅仅是一种测试的手段，是否保证质量，和测试手段没啥关系，其主要取决于用例设计是否完整、覆盖面是否全。自动化测试同手工测试一样，是一种测试手段，本身也是对手工测试的一种补充。



**做自动化测试，需要满足一些基本条件：**

1. **长期性**
   指的是被测产品（或功能）是否需要一个长期的维护，因为短期的项目是没有实现自动化测试的必要的，短期的项目很明显他的投入成本肯定大于其收益。

　　2. **稳定性**
　　被测产品（或功能）是否有一个相对稳定的产品。如果功能和界面都处于不稳定阶段而且经常发生变化的，那脚本和用例的维护成本是非常高，因此不建议在此阶段实施自动化。
　　4. **人员和工具**
　　就是说当前团队内部是否有具有实施自动化能力的人员，因为如果没有这样的工程师，那么仅凭意志力去做，可能花费的人力和时间成本极高；同时该工程师使用到的工具或者脚本依赖的语言是否是利于团队内部赋能，比如那种生涩难懂的语言，是很难在内部推广开来的，那么仅有该工程师一个人去搭建、维护，那么带来的价值也是极其有限的。
　　5. **有效的用例设计**
　　自动化测试所能带来的收益，很大程度上取决于测试用例，用例覆盖的面越广、针对同一功能点测试的维度越多，那么就越容易发现在产品迭代中引入的新问题。



## 求职者的不足

> 企业喜欢问求职者弱点，但精明的求职者一般不直接回答。我们可以再次强调自己的优势，然后表诉一些在新业务方面的经验问题。

通过目前我对应聘岗位的了解以及和前两轮技术面试官的沟通，首先我认为我是有能力也有信心能够胜任这个岗位，但目前的问题是新岗位的业务对我来说，以前接触较少，经验积累方面比较欠缺。但是这个问题，我相信我能够在入职后通过主动学习了解产品业务、请教同事等方式，快速熟悉业务，以最短的时间上手工作。



## 如何在新公司快速开展工作

1. 首先学习了解公司的规章流程制度，尤其是员工必知必守的不能触碰的红线；其次是公司的企业文化，主动学习了解，并融入到这样的团队中来。（当然，这一点基本在新员工入职时，会有专人培训讲解）
2. 调整心态。一是要有一个优雅的接受批评的心态，因为来到新环境可能会有一些低级错误，我们要不怕犯错，而是主动去解决问题，避免下次再犯；二是要有一个打攻坚战的心态，在新的公司，自己在业务上、流程上很多东西不熟悉，我们除了要敢于面对自己挖的坑，更要主动的花时间去学习、去请教，尽快的熟悉上手，完全的融入到团队中来。
3. 为了尽快的上手，介入到测试工作中，可以从以下几个方面来回答：
   1. 学习了解公司产品的业务流程、实现逻辑等。可以通过公司的需求文档、技术文档，同时多向师兄、前辈们请教业务中的一些具体细节和主要注意的点；
   2. 在了解了公司主要业务的基础上，还需要了解公司的研发流程规范，比如提测标准、BUG处理流程等；
   3. 在了解了前面的业务逻辑、流程规范之后，就需要了解公司目前开发测试用到的技术栈以及详细的测试流程，同时在测试过程中对测试人员有哪些具体要求；
   4. 再之后，就是参与到当前的需求中来，需求评审、提取测试点、输出测试用例、用例执行、BUG跟踪回归、输出报告等工作。





## 测试如何处理开发否认的BUG

首先，将BUG提交到缺陷管理库里面进行备案。如果后续确实不是BUG，那么对应开发直接拒绝关闭即可。

然后，要获取判断BUG的依据和标准，说服开发同学：

- 根据需求文档、产品说明书、设计文档等，确认实际结果是否与产品需求不一致的地方，提供缺陷的直接依据；
- 如果没有文档依据，可以根据相似的软件或者软件的一般特性来说明是否存在不一致的地方，来确认是否是缺陷；
- 如果确实没有文档依据，也没有类比产品，那么可以根据需求的实际使用场景、用户的使用习惯等方面考虑是否是缺陷；
- 如果通过上述方式已经证明是缺陷，却仍然存在争议，则可以拉上产品人员、需求方等一同探讨，给出明确的方案；
- 如果仍然存在争议，那么可以请求测试leader、研发leader、产品leader等介入，明确需求，确认BUG。

合理的论述，以推动问题解决为目的，保证客观、严谨、实事求是，不参杂个人情绪。



## BUG分析案例

**BUG描述：**

​		最近测试CRM商户管理中的注销商户，其实这个BUG有一定的机缘巧合，如果严格按照规范的操作，且后端数据安全做得到位的话，基本发现不了这个问题。

​		BUG其实就是我们在注销商户时，后端返回server error，删除失败。当时还挺纳闷，我直接重新创建一个商户，创建商户时需要完成三要素的校验（法人姓名、营业执照号、法人身份证号），同一法人的同一个营业执照只能注册一个商户。当我直接注销新创建的商户时，又是可以成功的。这个时候抓包看了两次前端提交的数据都是传的三要素信息给后端，这个时候，就开始怀疑是上一条测试数据的问题。

**定位BUG：**

​		后面就开始去kibana上面查看系统日志，在测试环境重复前面的操作，从日志打印看到后端报 server error 的原因是出现了数据库异常（SQL 语法错误）导致的，但是日志上并没有记录具体的异常SQL。这个时候就去找了开发，问他的代码分支，将其代码pull到本地，根据API接口找到对应的业务代码，在代码中就找到了问题的根因。这里前端请求过来之后，后端拿到三要素信息，通过营业执照号 SELECT 出对应的商户ID，然后执行 UPDATE  WHERE ID 等于 语句修改当前商户的标识为 已注销。按照正常逻辑，一个营业执照号，只会属于唯一的商户，这个逻辑是没问题的，但是由于是测试环境，我们营业执照号都是从网上找的，经常就用那么几个，很多时候测试为了快速创建商户直接修改的数据库，这就导致在SELECT 时，查询到多个商户ID，最后导致UPDATE语句中WHERE后面的等于不合法而报错。

**分析BUG：**

​		这个 BUG 虽然有一定的巧合性，但是这里有两个问题是客观存在的。

​		1、生产环境上，可能会因为用户多次点击创建商户、网络延迟、数据同步等问题，导致商户不唯一，因此需要增加处理逻辑，当SELECT到多个商户ID时，给出提示信息，让用户联系管理员，由管理员的超级权限来注销；

​		2、优化 UPDATE 语句，将 等号 修改整 in。当 in 后面是多个值时，需要校验管理员权限；
**总结：**
​		遇到 BUG 最好要有对比数据，这样能够尽快缩小问题范围，然后通过抓包分析接口的输入输出是否都OK，最后就是要养成查看日志，查看源码的习惯。

​		同时提醒我们在测试时，尤其是在新增、录入数据时，要加强数据一致性的测试，尽量都做一下并发测试。





## 人员管理

Hire标准：

1. 业务能力，像测试理论、场景设计、缺陷跟进等
2. 测试技术，脚本能力、开源工具、非功能测试能力
3. 领域知识，服务端、客户端、金融支付、AI效果测试等业务背景是否契合
4. 抗压能力，过往工作压力和当前业务是否匹配
5. 工作预期，下一份工作希望接触哪些业务或提升什么技能，没有想法的人慎用
6. 发展规划，候选人要对自己的成长目标有认真思考，达成路径可以看大概，没有规划的人慎用



Fire标准：

1. 业务交付，是否出现严重线上问题
2. 专业敬业，交代的任务是否可以独立完成好，是否积极主动承担更多的、有挑战性的任务
3. 改进创新，对业务流程、测试技术上是否有自己的思考并推动改进，对新的测试范式、测试技术或工具是否主动引入
4. 团队协作，横向跟产品、开发的写作上是否高效，有没有负反馈，以及内部的沟通协作
5. 成长提升，在工作中业务知识、技能技术是否有主动去提升的意识，是否真的有所成长能独当一面
